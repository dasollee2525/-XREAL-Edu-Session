{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### install packages(Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4\n",
    "pip install selenium\n",
    "pip install tqdm\n",
    "pip install pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from tqdm.notebook import trange\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 설명을 위한 세부 항목 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분석하고자 하는 데이터 열(column)을 지정\n",
    "#리뷰 작성 날짜\n",
    "Date = []\n",
    "#리뷰 내용\n",
    "Content = []\n",
    "#리뷰 유익성\n",
    "Helpful = []\n",
    "#추천 여부\n",
    "Recommend = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broswer = webdriver.Chrome(\"./chromedriver 2\")\n",
    "broswer.maximize_window()\n",
    "#------------------------데이터를 수집하고자 하는 URL------------------------\n",
    "url = \"https://steamcommunity.com/app/1811260/reviews/?browsefilter=toprated&snr=1_5_100010_\"\n",
    "broswer.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = broswer.page_source\n",
    "soup = bs(html, 'lxml')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page =\"page\"+str(1)\n",
    "print(soup.find(\"div\", id=page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Content = []\n",
    "contents = soup.find(\"div\", id=page).find_all(\"div\", {\"class\" : \"apphub_CardTextContent\"})\n",
    "print(contents)\n",
    "\n",
    "for i in contents:\n",
    "    temp = str(i).find(\"</div>\")\n",
    "    p = str(i)[temp+6:-6]\n",
    "    token = ['\\t', '\\n', '<br/>', '<b>', '</b>']\n",
    "    for removeStr in token:\n",
    "        p = p.replace(removeStr, \"\")\n",
    "    Content.append(p)\n",
    "\n",
    "print(Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = soup.find(\"div\", {'id' : page}).find_all(\"div\", {\"class\" : \"date_posted\"})\n",
    "\n",
    "for i in dates:\n",
    "    d = str(i).replace('<div class=\"date_posted\">Posted: ', '').replace('</div>', '')\n",
    "    print(d)\n",
    "    Date.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpfuls = soup.find(\"div\", {'id': page}).find_all(\"div\", class_=\"found_helpful\")\n",
    "\n",
    "for i in helpfuls:\n",
    "    h = str(i).replace('<div class=\"found_helpful\">', '').lstrip()\n",
    "    len = h.find(' ')\n",
    "    Helpful.append(h[:len])\n",
    "\n",
    "print(Helpful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommends = soup.find(\"div\", {'id': page}).find_all(\"div\", class_=\"title\")\n",
    "\n",
    "for i in recommends:\n",
    "    r = str(i).replace('<div class=\"title\">', '').replace('</div>', '')\n",
    "    Recommend.append(r)\n",
    "print(Recommend)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scrapper 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분석하고자 하는 데이터 열(column)을 지정\n",
    "#리뷰 작성 날짜\n",
    "Date = []\n",
    "#리뷰 내용\n",
    "Content = []\n",
    "#리뷰 유익성\n",
    "Helpful = []\n",
    "#추천 여부\n",
    "Recommend = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrapping(p_num):\n",
    "    html = broswer.page_source\n",
    "    soup = bs(html, 'lxml')\n",
    "\n",
    "    page = \"page\"+str(p_num)\n",
    "\n",
    "    contents = soup.find(\"div\", id=page).find_all(\"div\", {\"class\" : \"apphub_CardTextContent\"})\n",
    "  \n",
    "    for i in contents:\n",
    "        temp = str(i).find(\"</div>\")\n",
    "        p = str(i)[temp+6:-6]\n",
    "        #------------------없애고 싶은 단어----------\n",
    "        token = ['\\t', '\\n', '<br/>', '<b>', '</b>']\n",
    "        for removeStr in token:\n",
    "            p = p.replace(removeStr, \"\")\n",
    "        Content.append(p)\n",
    "\n",
    "    dates = soup.find(\"div\", {'id' : page}).find_all(\"div\", {\"class\" : \"date_posted\"})\n",
    "\n",
    "    for i in dates:\n",
    "        d = str(i).replace('<div class=\"date_posted\">Posted: ', '').replace('</div>', '')\n",
    "        Date.append(d)\n",
    "\n",
    "    helpfuls = soup.find(\"div\", {'id': page}).find_all(\"div\", class_=\"found_helpful\")\n",
    "\n",
    "    for i in helpfuls:\n",
    "        h = str(i).replace('<div class=\"found_helpful\">', '').lstrip()\n",
    "        len = h.find(' ')\n",
    "        Helpful.append(h[:len])\n",
    "\n",
    "    recommends = soup.find(\"div\", {'id': page}).find_all(\"div\", class_=\"title\")\n",
    "\n",
    "    for i in recommends:\n",
    "        r = str(i).replace('<div class=\"title\">', '').replace('</div>', '')\n",
    "        Recommend.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broswer = webdriver.Chrome(\"./chromedriver 2\")\n",
    "broswer.maximize_window()\n",
    "#데이터를 수집하고자 하는 URL\n",
    "url = \"https://steamcommunity.com/app/1811260/reviews/?browsefilter=toprated&snr=1_5_100010_\"\n",
    "broswer.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 문서 높이를 가져와서 저장\n",
    "prev_height = broswer.execute_script(\"return document.body.scrollHeight\")\n",
    "p_num = 0\n",
    "#-----------스크롤 횟수-------------\n",
    "final_pnum = 10\n",
    "#------로딩을 기다리는 시간(초)----\n",
    "sec = 5 \n",
    "\n",
    "# 반복 수행\n",
    "for _ in trange(final_pnum):\n",
    "# 스크롤 가장 아래로 내림\n",
    "    broswer.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "    p_num = p_num + 1\n",
    "\n",
    "# 페이지 로딩 대기\n",
    "    time.sleep(sec)\n",
    "    Scrapping(p_num)\n",
    "\n",
    "# 현재 문서 높이를 가져와서 저장\n",
    "    curr_height = broswer.execute_script(\"return document.body.scrollHeight\")\n",
    "    if curr_height == prev_height:\n",
    "        break\n",
    "\n",
    "    prev_height = curr_height"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcd6c753f6c428b4a317ffcba11f4bc0ae1ac07019fa225558fd28392129b165"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
